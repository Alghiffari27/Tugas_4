{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tLGa4ljxUjz",
        "outputId": "95938627-5aea-43de-962c-b37ee6af7f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/kilianovski/spoonvsfork?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.07M/9.07M [00:00<00:00, 78.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/kilianovski/spoonvsfork/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kilianovski/spoonvsfork\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import IPython.display as display\n",
        "\n",
        "# Cek apakah eager execution aktif\n",
        "print(\"Eager execution aktif:\", tf.executing_eagerly())\n",
        "\n",
        "# Cek apakah GPU tersedia\n",
        "print(\"GPU tersedia:\", len(tf.config.list_physical_devices('GPU')) > 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_oZMoweApBX",
        "outputId": "4e22555e-e80f-41dd-fec9-8fde244d57f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager execution aktif: True\n",
            "GPU tersedia: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set seed agar hasil acak bisa direproduksi\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n"
      ],
      "metadata": {
        "id": "GyaZKzP7B1Ru"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join\n",
        "\n",
        "# Langkah 1: Dapatkan path dari kagglehub\n",
        "path = kagglehub.dataset_download(\"kilianovski/spoonvsfork\")\n",
        "print(\"Path dari kagglehub:\", path)\n",
        "\n",
        "# Langkah 2: Telusuri isi folder\n",
        "print(\"Isi dari path:\", os.listdir(path))\n",
        "\n",
        "# Langkah 3: Masuk ke subfolder 'spoon-vs-fork'\n",
        "basedir = join(path, 'spoon-vs-fork')\n",
        "print(\"Isi basedir:\", os.listdir(basedir))\n",
        "\n",
        "# Langkah 4: Akses folder spoon dan fork\n",
        "fork_dir = join(basedir, 'fork')\n",
        "spoon_dir = join(basedir, 'spoon')\n",
        "\n",
        "# Langkah 5: Baca semua gambar\n",
        "spoon_paths = [join(spoon_dir, f) for f in os.listdir(spoon_dir) if f.endswith(('.jpg', '.png'))]\n",
        "fork_paths = [join(fork_dir, f) for f in os.listdir(fork_dir) if f.endswith(('.jpg', '.png'))]\n",
        "img_paths = spoon_paths + fork_paths\n",
        "\n",
        "print(\"Jumlah gambar sendok:\", len(spoon_paths))\n",
        "print(\"Jumlah gambar garpu :\", len(fork_paths))\n",
        "print(\"Total gambar        :\", len(img_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY_8kXnDDU8G",
        "outputId": "891d33a3-9264-4ea9-ca6d-877b3ff56aa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path dari kagglehub: /kaggle/input/spoonvsfork\n",
            "Isi dari path: ['spoon-vs-fork']\n",
            "Isi basedir: ['spoon', 'fork', 'spoon-vs-fork']\n",
            "Jumlah gambar sendok: 144\n",
            "Jumlah gambar garpu : 186\n",
            "Total gambar        : 330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from os.path import join\n",
        "\n",
        "def load_data(basedir):\n",
        "    folders = [f for f in os.listdir(basedir) if os.path.isdir(join(basedir, f))]\n",
        "    print(\"Folder label ditemukan:\", folders)\n",
        "\n",
        "    result = pd.DataFrame(columns=['filename', 'class'])\n",
        "\n",
        "    for folder in folders:\n",
        "        folder_path = join(basedir, folder)\n",
        "        files = [join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.jpg', '.png'))]\n",
        "        df = pd.DataFrame({'filename': files, 'class': folder})\n",
        "        result = pd.concat([result, df], ignore_index=True)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "nST3PqiTDa98"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basedir = join(path, 'spoon-vs-fork')  # dari sebelumnya\n",
        "\n",
        "image_df = load_data(basedir)\n",
        "print(image_df.head())\n",
        "print(\"Total gambar:\", len(image_df))\n",
        "print(\"Kelas unik:\", image_df['class'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JhPzGpoDvYg",
        "outputId": "fd94f323-3df6-455e-aa62-493c8eb4e659"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder label ditemukan: ['spoon', 'fork', 'spoon-vs-fork']\n",
            "                                            filename  class\n",
            "0  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "1  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "2  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "3  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "4  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "Total gambar: 330\n",
            "Kelas unik: ['spoon' 'fork']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_data(image_df):\n",
        "    allowed_extensions = ['jpg', 'jpeg', 'png', 'gif']\n",
        "\n",
        "    def is_valid_image(filename):\n",
        "        extension = os.path.splitext(filename)[1][1:].lower()\n",
        "        return extension in allowed_extensions\n",
        "\n",
        "    invalid_files = image_df[~image_df['filename'].apply(is_valid_image)]\n",
        "\n",
        "    # Log file yang dihapus\n",
        "    for img in invalid_files['filename']:\n",
        "        ext = os.path.splitext(img)[1][1:].lower()\n",
        "        print(f\"Removed file with extension '{ext}' — {img}\")\n",
        "\n",
        "    # Hapus baris tidak valid\n",
        "    return image_df[image_df['filename'].apply(is_valid_image)].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "6QVmecWLD2u5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df = validate_data(image_df)\n",
        "print(\"Jumlah gambar valid:\", len(image_df))\n",
        "print(image_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA9BIcIBEBZp",
        "outputId": "60583906-0d73-475f-c4f4-bf0b941070b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah gambar valid: 330\n",
            "                                            filename  class\n",
            "0  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "1  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "2  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "3  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n",
            "4  /kaggle/input/spoonvsfork/spoon-vs-fork/spoon/...  spoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TP5QGtwAEHTN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    image_df.filename,\n",
        "    image_df['class'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=image_df['class']  # menjaga proporsi spoon vs fork\n",
        ")\n"
      ],
      "metadata": {
        "id": "t83E6z7vEj2R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "test_df = pd.DataFrame({'filename': X_test, 'class': y_test})\n",
        "\n",
        "print(\"Jumlah data latih:\", len(train_df))\n",
        "print(\"Jumlah data uji  :\", len(test_df))\n",
        "print(\"Distribusi kelas (train):\")\n",
        "print(train_df['class'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5MvJib7ElxJ",
        "outputId": "38fc3fbe-8b6b-41dd-9e53-7fa60a49a5c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data latih: 264\n",
            "Jumlah data uji  : 66\n",
            "Distribusi kelas (train):\n",
            "class\n",
            "fork     149\n",
            "spoon    115\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "resnet = ResNet50(include_top=False, pooling='avg', weights='imagenet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLOLHYzwFMHP",
        "outputId": "8aa2650a-ec9f-4865-d4af-a5438c589305"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# Inisialisasi ResNet50 tanpa top layer, dengan bobot ImageNet\n",
        "resnet = ResNet50(include_top=False, pooling='avg', weights='imagenet')\n",
        "\n",
        "# Bangun model klasifikasi 2 kelas\n",
        "resnet_model = Sequential([\n",
        "    resnet,\n",
        "    Dense(2, activation='softmax')  # output 2 kelas: spoon dan fork\n",
        "])\n",
        "\n",
        "# Bekukan layer ResNet (tidak dilatih ulang)\n",
        "resnet.trainable = False\n"
      ],
      "metadata": {
        "id": "lI3N7KH3FRm_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "zwz3vvLSGQwF",
        "outputId": "24bbbb1f-99a0-4a2e-82fb-5061ec7a993f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m4,098\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,591,810\u001b[0m (90.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,810</span> (90.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,098\u001b[0m (16.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> (16.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Generator dengan augmentasi untuk training\n",
        "train_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "# Generator tanpa augmentasi untuk validasi\n",
        "valid_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# DataFrame training\n",
        "train_df = pd.DataFrame({'filename': X_train, 'class': y_train})\n",
        "test_df = pd.DataFrame({'filename': X_test, 'class': y_test})\n",
        "\n",
        "# Flow training\n",
        "train_flow = train_gen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    directory=None  # karena path-nya sudah full\n",
        ")\n",
        "\n",
        "# Flow validasi\n",
        "valid_flow = valid_gen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    directory=None\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17GZKBur3Nld",
        "outputId": "9c1fdf14-0196-4a92-cb8f-69cf219d21d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 264 validated image filenames belonging to 2 classes.\n",
            "Found 66 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='categorical_crossentropy',  # karena class_mode='categorical'\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "DnuE3EjtJ4be"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Generator\n",
        "train_gen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "valid_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Flow from dataframe\n",
        "train_flow = train_gen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "valid_flow = valid_gen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    class_mode='categorical',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Compile model\n",
        "resnet_model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Fit model (pakai fit, BUKAN fit_generator)\n",
        "resnet_model.fit(\n",
        "    train_flow,\n",
        "    validation_data=valid_flow,\n",
        "    epochs=8,\n",
        "    steps_per_epoch=len(train_flow),\n",
        "    validation_steps=len(valid_flow)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Fhig_zC3vAi",
        "outputId": "493b49a9-3496-46e1-c26d-ea2260a5d840"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 264 validated image filenames belonging to 2 classes.\n",
            "Found 66 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.6225 - loss: 0.6648 - val_accuracy: 0.8788 - val_loss: 0.2768\n",
            "Epoch 2/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.9601 - loss: 0.1567 - val_accuracy: 0.9394 - val_loss: 0.2092\n",
            "Epoch 3/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 3s/step - accuracy: 0.9729 - loss: 0.1119 - val_accuracy: 0.9242 - val_loss: 0.2165\n",
            "Epoch 4/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.9755 - loss: 0.0881 - val_accuracy: 0.9242 - val_loss: 0.2319\n",
            "Epoch 5/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.9913 - loss: 0.0688 - val_accuracy: 0.9394 - val_loss: 0.2066\n",
            "Epoch 6/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.9939 - loss: 0.0662 - val_accuracy: 0.9242 - val_loss: 0.2048\n",
            "Epoch 7/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9958 - loss: 0.0549 - val_accuracy: 0.9545 - val_loss: 0.1917\n",
            "Epoch 8/8\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step - accuracy: 0.9951 - loss: 0.0492 - val_accuracy: 0.9091 - val_loss: 0.2246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79eb028d4850>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}